### AICoreDirector 介绍讲稿

---

### 1）开场
今天介绍 AICoreDirector——一个面向企业与开发团队的“AI基础能力中枢”。它的使命是用一个统一的入口，把多家大模型、传统ML服务与自研AI能力连接起来，做到智能调度、统一治理、可观可管，帮助业务更快、更稳、更省钱地用上AI。

---

### 2）背景与痛点
围绕“企业级模型服务层”的真实环境，痛点不仅来自 LLM，还来自两大类资产：公司积累的 AI 组件与传统 ML 模型服务。总体呈现为“多源异构、难以治理、难以度量、难以复用”。

- 能力来源多元且异构
  - 上游包括三类：多家 LLM 供应商、自研 AI 组件（抽取、分类、生成等）、传统 ML 服务（REST/gRPC）。
  - 协议/鉴权/数据格式/流式能力不一致，集成成本高、上层改造重。

- 服务治理与合规要求高
  - 需统一的限流/配额、SLA/SLO、重试/熔断/降级、审计与追踪。
  - 数据主权与合规（隐私脱敏、内容安全、留痕审计、等保/GDPR）要求难以在多服务间一致落地。

- 成本与效果难平衡
  - Token/调用成本差异大且波动，缺乏按用户/应用/模型的细粒度成本归集与预算控制。
  - 需要在“成本、延迟、效果”间动态权衡与自动化路由。

- 版本与灰度困难
  - 模型/插件/服务版本众多，缺少灰度发布、A/B 测试、快速回滚与可比性评估的统一机制。

- 可观测性与运维割裂
  - 健康、QPS、延迟、错误率、命中率、成本等指标分散在各处，缺少端到端可观测与统一告警。

- 复用沉淀不足
  - 提示词工程、行业模板、业务插件难以沉淀与共享，重复造轮子、经验不可迁移。

- 多租户与权限隔离
  - 团队/项目级隔离、RBAC/细粒度授权、密钥管理与轮换难统一。

- 传统 ML 特有痛点
  - 特征一致性与数据/模型漂移监测、在线/离线一体化、批处理与在线推理的 SLA 差异、GPU 资源与队列治理。

过渡：这些挑战的共因是——缺少一个“中枢”。这正是 AICoreDirector 的定位。

---

### 3）定位与电梯陈述
- 定位：企业AI能力的“总线与中枢”，统一接入、智能调度、统一管控。
- 一句话：把所有AI能力收拢到一个入口里，让业务只需“用”，不用再“管”。

---

### 4）产品全景
- 统一入口 API：对上统一 REST 接口；对下路由到 LLM、插件或注册的外部服务。
- 模型池与智能路由：按标签、业务等级、健康状态、QPS、成本等选择“更合适”的模型；内置主备与回退策略。
- 插件化与服务注册：业务插件可热插拔；外部ML/AI服务通过注册即“入池”；平台统一代理与调用。
- 提示词模板中心：集中管理 Prompt（ini/yaml/json），热加载，前后端可共用。
- 监控与成本治理：健康、QPS、命中次数、Token与成本统计，支持按用户/应用聚合。
- 前端控制台：仪表盘、LLM配置、插件管理、服务发现、Prompt管理、历史记录等。

---

### 5）六大亮点
- 多模型统一管理（LLM池）
  - 标准化模型元数据（名称、URL、Key、标签、版本、QPS、成本、健康等）。
  - 支持动态增删改、热加载；内置健康检查与QPS控制。
- 智能路由与自适应调度
  - 路由优先级：明确 `model_name` > 会话偏好 > 业务等级 > 成本偏好 > 标签 > 健康/延迟/错误率/并发综合评分。
  - 评分机制：错误率>延迟>成本>并发，优先选择“当前最合适”的模型。
  - Fallback 回退：失败自动切换备选模型，提高稳定性。
- 插件生态与热插拔
  - 插件只需加 `@plugin_api` 即自动注册为 API；无需手动路由。
  - 支持两种调用入口：
    - 直接路由：`POST /{plugin_name}`
    - 统一入口：`POST /plugin/invoke?plugin_name=...`（支持批量与并发；自动注入 `llm_context`）
  - 热加载线程监控 `business/` 变更，自动扫描、自动补注册，迭代快速。
- 服务注册与动态路由
  - 外部AI/ML服务通过 `/service-registry/register` 注册；平台自动纳管与健康探测。
  - 动态代理：上层直接 `POST /服务名` 即可调用后端服务。
- 提示词模板中心
  - 集中存储与管理 Prompt 模板，支持分组、热加载、API/前端增删改查。
  - 让“提示词工程”成为组织级资产，方便沉淀、A/B与复用。
- 可观可管的监控与成本治理
  - QPS、命中数、成本、健康状态可视化；支持按用户/应用聚合成本，便于分账与预算控制。
  - 前端仪表盘支持趋势图、健康状态视图、调用历史，帮助技术与业务共识化运营。

---

### 6）架构与关键模块
- API服务层：统一入口，参数校验、路由分发、异常处理；提供核心接口：
  - `/llm_invoke`、`/plugin/invoke`、`/service-registry/register`、`/service-discovery/list`、`/plugin/list` 等。
- 业务逻辑层：会话管理、模型选择、Prompt处理、批量并发调度等。
- LLM池与路由器：统一管理模型实例与状态；根据策略选择模型；计数并发与QPS，配合健康检查工作。
- 健康检查与监控：定时探测健康、记录QPS与调用历史，实时更新状态。
- 插件加载器（注册与调用两个独立流程）
  - 注册（启动/热加载）：扫描 `business/*.py`，执行 `@plugin_api`，把函数注册到 `plugin_registry` 并挂载为 `/{func_name}` 路由（见 `core/plugin_loader.py`）。
  - 调用（请求时）：
    - 直接路由：`POST /{plugin_name}`，由 `get_plugin_func` 动态生成的 FastAPI handler 解析 Body 并调用函数；
    - 统一入口：`POST /plugin/invoke?plugin_name=...`，支持批量/并发与上下文注入（`llm_context`）。
- 提示词模板中心（`core/prompt_manager.py`）：从 `config_prompts/` 加载模板；API/前端双向编辑；与插件/业务逻辑无缝对接。
- 状态与统计（`core/state_manager.py`、`core/statistics.py`）：管理会话偏好模型，记录命中、成本、历史，支撑精细化治理。

---

### 7）典型应用场景
- 企业级AI中枢
  - 企业内各种AI服务统一接入；应用端只对接 AICoreDirector，显著降低耦合与维护成本。
- 软件公司/ISV 平台化输出
  - 为SaaS产品/项目制交付提供统一AI能力底座；插件化扩展业务，提升交付效率与可复用。
- 多云/混合云治理
  - 同时对接多家模型与私有模型，按成本与合规在多云间智能切换。
- 内容抽取/标签化/摘要/分类
  - 通过插件+Prompt模板快速实现行业化能力沉淀，平滑替换与升级底层模型。
- 成本敏感与高可用业务
  - 经济业务优先低成本模型；关键业务优先高效果/低延迟模型；异常自动回退，服务不中断。

---

### 8）差异化与可持续优势
- 设计上的“中枢”定位，强调对上“统一治理”、对下“多源适配”，而非单一模型或工具箱。
- 内建“成本与效果并重”的路由哲学，可配置、可度量、可演进。
- 开发者友好：插件即API、热加载、批量与并发调度、Prompt中心，极大降低试错与迭代成本。
- 运维友好：健康、QPS、命中、成本一体化可观测，支撑企业级运营体系。
- 生态与开放：既能吸纳自研与第三方能力，也能向外开放为“能力平台”。

---

### 9）部署与商业化
- 部署形态
  - 开发/测试：本地快速起服务（FastAPI + 前端控制台）。
  - 生产：容器化部署、横向扩展；日志/监控对接企业平台（如 ELK、Prometheus/Grafana）。
- 商业化方向
  - 企业版增值：安全合规、细粒度权限、审计、SLA保障、专属支持。
  - 咨询与交付：模型选型、接入服务、场景落地、Prompt工程共创。
  - 生态伙伴：与系统集成商、咨询公司、云厂商联合方案。

---

### 10）路线图
- 短期（0-3个月）：完善服务发现/插件生态；强化流式接口与并发治理；补齐行业模板。
- 中期（3-9个月）：多模态（图像/语音/视频）接入；更智能的自适应路由（结合历史效果与在线学习）。
- 中长期（9-18个月）：生态市场化（插件/模型市场）；更强的安全与审计；多组织多租户；国际化与多语言。

---

### 11）总结与行动建议
AICoreDirector 用“统一入口 + 智能路由 + 插件/服务生态 + 监控与成本治理”四根支柱，构建企业AI的“总线与中枢”。它把“集成复杂、治理分散、成本不可控”的问题，变为“标准化接入、智能化调度、可观可管”的能力。建议大家从一个小场景开始（如文档抽取与分类），快速集成与验证，再逐步放大覆盖面。

---

### 12）Q&A 引导
欢迎就三类问题提问：
- 具体接入流程与改造成本；
- 路由策略/成本治理如何落地到你们的业务；
- 插件生态与行业模板如何共建。

---

#### 附：演示建议
- 控制台快速演示：Dashboard、LLM配置、插件管理、服务发现、Prompt管理、调用历史。
- API 小样：`/llm_invoke`（含 `stream`）与 `/plugin/invoke`（含批量）。
- 插件热加载：在 `business/` 新增 `@plugin_api` 函数，触发热加载并演示新路由生效。


